# Week 4 Coding Challenge: Training your own sentiment classifier

1. Build a classification model based on a simple LSTM architecture and train it on data from:  https://www.kaggle.com/datasets/marklvl/sentiment-labelled-sentences-data-set
   
2. How does it perform on [Dostoevsky](https://github.com/christianvedels/News_and_Market_Sentiment_Analytics/blob/main/Lecture%201%20-%20Introduction/Coding_challenge1.md) from the first coding challenge? Does it perform better than the off-the-shelf models? 

3. Bonus: Try using BERT (or similar) instead of LSTM. 


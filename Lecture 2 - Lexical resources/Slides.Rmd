---
title: "News and Market Sentiment Analytics"
subtitle: "Lecture 2: Lexical resources"
author: 'Christian Vedel,<br> Department of Economics<br><br>
Email: christian-vs@sam.sdu.dk'
date: "Updated `r Sys.Date()`" 
output:
  xaringan::moon_reader:
    includes:
      after_body: insert-logo.html
    self_contained: false
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=TRUE, include=TRUE, cache=TRUE)
library(reticulate)
use_condaenv("sentimentF23")
```

```{python include=FALSE}
import nltk
```



```{css echo=FALSE}
.pull-left {
  float: left;
  width: 48%;
}
.pull-right {
  float: right;
  width: 48%;
}
.pull-right ~ p {
  clear: both;
}


.pull-left-wide {
  float: left;
  width: 66%;
}
.pull-right-wide {
  float: right;
  width: 66%;
}
.pull-right-wide ~ p {
  clear: both;
}

.pull-left-narrow {
  float: left;
  width: 30%;
}
.pull-right-narrow {
  float: right;
  width: 30%;
}

.small123 {
  font-size: 0.80em;
}

.large123 {
  font-size: 2em;
}

.red {
  color: red
}
```


# Last time
.pull-left[
- Course overview
- How did we get to ChatGPT? (And what are the implications)
- An example of some research I do using the techniques of the course
]

.pull-right[
![Trees](Figures/Trees.jpg)
]

---
# Today's lecture
.pull-left[
- Lexical Resources
- Finn Ã…rup Nielsen 
- Basic workings of NLTK
- Coding challenge: Working with Text Data
]

---
# A basic problem
Consider the headline 

> "Novo Nordisk reported a modest increase in earnings, but analysts remain cautious."

- "the," "a," and "in" are stopwords that don't provide financial context
- "earnings" and "cautious" are important terms for stock prediction 
- Removing stopwords helps focus on the financially relevant content

Noise in $\rightarrow$ noise out  
Clean data in $\rightarrow$ clean results out


---
# Lexical resources
.pull-left-narrow[
- Why do we have to do the work, if someone has already done it? 

]

.pull-right-wide[
#### Stopwords
```{python}
from nltk.corpus import stopwords
stopwords.words('english')
```

#### Computing conent fraction

```{python}
from nltk.corpus import gutenberg
def content_fraction(text):
  stopwords = nltk.corpus.stopwords.words('english')
  content = [w for w in text if w.lower() not in stopwords]
  return len(content) / len(text)
emma = gutenberg.words("austen-emma.txt")
content_fraction(emma)
```


]

---
# AFINN package
.pull-left[
- Afinn github: https://github.com/fnielsen/afinn
- Live Afinn: https://darenr.github.io/afinn/
> "That would have been splendid. It would have been absolutely amazing. The best there ever was. But it was not."
- 'best': 3, 'amazing': 4, 'splendid': 3

]

.pull-right[
![Finn](https://avatars.githubusercontent.com/u/484028?v=4)
*https://github.com/fnielsen*
]

---
# A very simple sentiment analysis
.pull-left[
- What if we just count positive/negative words? 

### Advatages 
- You can explain this to anyone 
- Works supprisingly well 

### Disadvantages 
- Cannot understand context 
  + "Bull" is positive in finance
  + "Bull" is neutral/negative in everyday conversation
- Typos and spelling mistakes are unhandled 
]

.pull-left[

]

---
# Trick 1: Stopwords 
Already covered

---
# Tricks 2: Stemming 
.small123[
.pull-left[
```{python}
import nltk
from nltk.stem import PorterStemmer

# Initialize the Porter Stemmer
stemmer = PorterStemmer()

# Example words for stemming
words = ["jumping", "jumps", "jumped", "jumper", "jumpingly"]

 # Stem the words
stemmed_words = [stemmer.stem(word) for word in words]
```
]

.pull-right[
```{python}
# Print the stemmed words
for original, stemmed in zip(words, stemmed_words):
    print(f"{original} -> {stemmed}")
```
]
]

---
# Tricks 3: Lemmatization
.pull-left[
- Relies on the idea of a semantic net 
- Each word with same meaning should be encoded the same 
- "car", "automobile", "automotive vehicle"
]
```{python}
from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
lemmatizer.lemmatize("rocks")
lemmatizer.lemmatize("corpora")
```

---
# A look insight WordNet

.pull-left[
```{python}
from nltk.corpus import wordnet as wn

# Synonomym names
wn.synsets('motorcar')

# Synonyms
wn.synset('car.n.01').lemma_names()
```
]


.pull-right[
![Wordnet](https://www.nltk.org/images/wordnet-hierarchy.png)
]
#### Example
> the boy's cars are different colors 
> $\Rightarrow$ the boy car be differ color


---
# More lexical relations
- Hypernyms and Hyponyms: 
  + 'Hypo': Below, 'Hyper': 
  + Above ('is a' relationship)
- Meronym and holonym: 
  + 'Mero': Parts, 
  + 'Holo': Whole (what it is part of)
  
Meronym of a 'tree': Trunk, Crown, Leaves 
Holonym of a 'tree': Forest 

Homonyms: 'saw', 'saw' 
 + Either *honomgraphs* or *homophones* (above is both)
 + Homophones: 'bow' (ship), 'bow' (act of politeness), 'bow' (pretty thing)
 + Homophones: 'cell', 'sell'

---
# Simple(st) sentiment analysis
*I will demonstrate a simple sentiment analysis in Python*

*See under '[Lecture 2 - Lexical resources/Code/](https://github.com/christianvedels/News_and_Market_Sentiment_Analytics/tree/main/Lecture%202%20-%20Lexical%20resources/Code)' '01_Get_stock_data.py', '02_Get_news_sentiment.py', '03_Stock_prices_and_sentiment'*

---
# The Zipf Mystery
*We will use basic NLP tools to investigate Zipfs law in the Gutenberg Corpus*

*See under '[Lecture 2 - Lexical resources/Code/](https://github.com/christianvedels/News_and_Market_Sentiment_Analytics/tree/main/Lecture%202%20-%20Lexical%20resources/Code)' '11_Zipf'*

**Zipf's law:**  

$$F_n = \frac{F_1}{n}$$

---
class: inverse, middle
# Coding challenge: 
## The Zipf Mystery
[Click here to submit](https://forms.gle/WmSEkZn8WH1fiDjE6 )

```{r echo=FALSE}
library(countdown)
source("../000_Misc_functions_for_slides.R")
vertical = 0.35
dist = 0.15

countdown(
  minutes = 35,
  seconds = 0,
  right = 0,
  top = ToPct(vertical)
)
# countdown(
#   minutes = 25,
#   seconds = 0,
#   right = 0,
#   top = ToPct(vertical + dist)
# )
```

---
# Next time
.pull-left[
- 'Structural' classification 
- Word tagging 
 
]

.pull-right[
![Trees](Figures/Trees.jpg)
]


